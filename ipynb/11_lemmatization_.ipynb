{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDTQwe8DR8i8"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Initialize the WordNet lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Lemmatize words\n",
        "words = [\"running\", \"ate\", \"better\"]\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "print(lemmatized_words)\n",
        "\n",
        "\n",
        "\n",
        "import spacy\n",
        "\n",
        "# Load English and French models\n",
        "nlp_en = spacy.load(\"en_core_web_sm\")\n",
        "nlp_fr = spacy.load(\"fr_core_news_sm\")\n",
        "\n",
        "# Sample sentences\n",
        "sentences_en = [\n",
        "    \"I am running in the park.\",\n",
        "    \"They are eating pizza.\",\n",
        "    \"The cat is sitting on the mat.\"\n",
        "]\n",
        "\n",
        "sentences_fr = [\n",
        "    \"Je cours dans le parc.\",\n",
        "    \"Ils mangent de la pizza.\",\n",
        "    \"Le chat est assis sur le tapis.\"\n",
        "]\n",
        "\n",
        "# Lemmatize English sentences\n",
        "print(\"English Lemmatization:\")\n",
        "for sentence in sentences_en:\n",
        "    doc = nlp_en(sentence)\n",
        "    lemmatized_words = [token.lemma_ for token in doc]\n",
        "    print(lemmatized_words)\n",
        "\n",
        "# Lemmatize French sentences\n",
        "print(\"\\nFrench Lemmatization:\")\n",
        "for sentence in sentences_fr:\n",
        "    doc = nlp_fr(sentence)\n",
        "    lemmatized_words = [token.lemma_ for token in doc]\n",
        "    print(lemmatized_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define a custom pipeline component for lemmatization\n",
        "@spacy.Language.component(\"custom_lemmatization\")\n",
        "def custom_lemmatization(doc):\n",
        "    for token in doc:\n",
        "        if token.pos_ in [\"VERB\", \"ADJ\", \"ADV\", \"NOUN\"]:\n",
        "            token.lemma_ = token.lemma_.lower()\n",
        "    return doc\n",
        "\n",
        "# Add the custom component to the pipeline\n",
        "nlp.add_pipe(\"custom_lemmatization\", last=True)\n",
        "\n",
        "# Print the updated pipeline\n",
        "print(\"Updated NLP Pipeline:\")\n",
        "for name, component in nlp.pipeline:\n",
        "    print(f\"{name}: {component}\")\n"
      ],
      "metadata": {
        "id": "KOH7LJwIU1DO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}